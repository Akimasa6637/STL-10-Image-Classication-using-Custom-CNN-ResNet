# **STL10 Image Classication using Custom CNN / ResNet**  
## ◆ プロジェクト概要
本プロジェクトでは、画像分類タスク用データセット「STL-10」を用いて、  
自作のニューラルネットワークモデルを構築・学習・評価・可視化を行いました。  

モデル構造は、  
AlexNetをべースに、ResNetのショートカット構造（Residual Block）  
を組み込んだCNNを自作し、精度および学習効率の向上を図りました。

自作モデル構築に関して、予測精度の向上とモデルの解釈性の向上を策定し、  
最終的にはResNet風CNNにより、**精度80.90%** を達成しました。

また、単なる精度向上に留まらず、  
「どうしてそのような判断をしたのか」を可視化できるモデル設計まで踏み込んだ、  
深い学びのある取り組みとなりました。


## ◇ 実施内容
**～ 全体 ～**  

* **データ拡張（Augmentation）**：**ランダムクリップ・左右反転** を中心に実施し、過学習の抑制および汎化性能の向上
* **入力画像の正規化**：平均と標準偏差を用いて正規化を行い、学習の安定性を向上
* **Class Activation Map（CAM）**：出力クラスごとの **注目領域** を可視化し、**モデル判断根拠** を可視化。

**～ AlexNet風CNN ～**
* **入力層 => 3層のConv層 => Global Average Pooling（GAP）** による構成
* Poolingでは、現代手法である **AdaptiveAvePool2d** を導入
* 全結合（FC）層は **1層のみ** とし、軽量かつ高速な推論を重視

**～ ResNet風CNN ～**
* **残差ブロック（Residual Block）・残差スタック（Residual Stack）** を実装
* ResNet34を参考に、全体で **24層構成** とし、深い学習を可能に
* **ショートカット接続** により勾配消失を緩和し、学習の収束速度と精度を大幅向上
* AlexNet風CNNと比較して、最終テスト精度が **80%以上まで改善**

## ◇ 実施結果
| モデル構成          | テスト精度（Top-1） | モデルサイズ    |
| -------------- | ------------ | -------------|
| AlexNet風CNN    | **74.65%**      | 31.53 MB     |
| ResNet風CNN（自作） | **80.90%**      | 164.85 MB     |

* **AlexNet風CNN** では、シンプルな構成（3層Conv + GAP + 1層FC）ながらも、**約74.65%のテスト精度** を達成。  
  基礎的なCNNとして一定の性能を発揮したものの、**深い特徴抽出や複雑なパターンの分類には限界** が見られた
  
* 一方、**自作ResNet風CNN** では、**残差接続による勾配の安定化と深層構造**により、  
  最終的に少ないデータ数で **80%を超える高精度** を達成。特に収束速度と汎化性能において明確な差を確認
  
* さらに、**Class Activation Mapping（CAM）による可視化** を行ったことで、  
  モデルが画像中の **どの領域に注目して分類しているか** を確認可能に。  
  ResNetモデルは対象物の **輪郭や本質的な特徴** に焦点を当てていることが分かり、モデルの解釈性も向上

## ◇ ファイル構成
* README.md: 本ファイル。プロジェクトの概要や構成を記載
* STL10_Classifier_a_la_AlexNet_Base.ipynb: AlexNet風CNNの構築・学習・評価・可視化
* STL10_Classifier_a_la_ResNet.ipynb: ResNet風CNNの構築・学習・評価・可視化

## ◇ ノートブック実行リンク
* STL10_Classifier_a_la_AlexNet_Base.ipynb（AlexNet風CNN）
  => [Google Colab で開く](https://colab.research.google.com/drive/1rVHDc_oGgn2btimpQCGlcZzIyOT9A_cB?usp=drive_link)

* STL10_Classifier_a_la_ResNet.ipynb（ResNet風CNN）
  => [Google Colab で開く](https://colab.research.google.com/drive/1WfsbF9_6IzCDgcyzyLTUPLFiiJDdIg7M?usp=drive_link)


## ◇ 学び・得られたこと
* データ拡張やCAMなど、モデルの可視化手法に **重点的に取り組んだ** ことで、実践的なスキルを体得
* Markdown形式での記述を交えながら、**アウトプットを通じて理解を深める習慣** が身についた
* AlexNet風モデル構築を通して、**「初期に情報を大きく圧縮し、その後に特徴を抽出していく」** 流れの重要性を理解
* ResNet風モデル構築においては、**残差ブロック（Residual Block）の概念** に触れ、深層ネットワークに対する視野が大きく広がった
* 実装面では、各処理を **関数化しながら構成** することで、コードの再利用性と可読性の高い実装スタイルを身につけることができた
---
最後までご覧いただき、ありがとうございました。  
今回の取り組みが、自分の深層学習モデルの設計や分析の礎となっていき、  
今後の学習に大きく貢献してくれるものだと思っております。
